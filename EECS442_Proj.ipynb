{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oF_O0fCrfkOf"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install moviepy transformers yt_dlp wget pytube\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Import necessary libraries\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import moviepy.editor as mp\n",
        "import wget\n",
        "import yt_dlp as youtube_dl\n",
        "import tensorflow as tf\n",
        "from google.colab import files\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (\n",
        "    Input,\n",
        "    ConvLSTM2D,\n",
        "    BatchNormalization,\n",
        "    Flatten,\n",
        "    Conv2D,\n",
        "    MaxPooling2D,\n",
        "    GlobalAveragePooling2D,\n",
        "    TimeDistributed,\n",
        "    Embedding,\n",
        "    LSTM,\n",
        "    Dense,\n",
        "    Dropout,\n",
        "    RepeatVector,\n",
        "    Add,\n",
        "    Activation,\n",
        "    Permute,\n",
        "    Reshape,\n",
        "    Softmax,\n",
        "    Dot\n",
        ")\n",
        "import pickle\n",
        "import glob\n",
        "import zipfile\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WvFF3n4J2T-"
      },
      "source": [
        "Download video and caption files from dataset and extract frames from video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLoo0eEaiyqI"
      },
      "outputs": [],
      "source": [
        "def download_dataset_files(video_urls_path=\"video_urls.txt\", captions_path=\"captions.txt\"):\n",
        "    # URLs for the data files (replace these with the actual links provided)\n",
        "    ## GET DATA HERE: https://ivi.fnwi.uva.nl/isis/mediamill/datasets/videostory.php\n",
        "    video_urls_link = \"https://isis-data.science.uva.nl/mediamill/videostory/content/datasets/VideoStory46K/urls.txt\"\n",
        "    captions_link = \"https://isis-data.science.uva.nl/mediamill/videostory/content/datasets/VideoStory46K/titles_stemmed.txt\"\n",
        "\n",
        "    try:\n",
        "        # Download the files if they do not already exist\n",
        "        if not os.path.exists(video_urls_path):\n",
        "            #print(f\"Downloading video URLs to {video_urls_path}...\")\n",
        "            wget.download(video_urls_link, video_urls_path)\n",
        "\n",
        "        if not os.path.exists(captions_path):\n",
        "            #print(f\"Downloading captions to {captions_path}...\")\n",
        "            wget.download(captions_link, captions_path)\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading dataset files: {e}\")\n",
        "\n",
        "def load_data(video_urls_path=\"video_urls.txt\", captions_path=\"captions.txt\"):\n",
        "    try:\n",
        "        with open(video_urls_path, 'r') as f:\n",
        "            video_urls = [line.strip() for line in f.readlines()]\n",
        "\n",
        "        with open(captions_path, 'r') as f:\n",
        "            captions = [line.strip() for line in f.readlines()]\n",
        "\n",
        "        return video_urls, captions\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error loading data: {e}\")\n",
        "        return [], []\n",
        "    except Exception as e:\n",
        "        print(f\"Unexpected error loading data: {e}\")\n",
        "        return [], []\n",
        "\n",
        "# Step 1: Download the video temporarily using youtube-dl\n",
        "def download_video_temp(url, temp_video_path=\"/content/temp_video.mp4\"):\n",
        "    ydl_opts = {\n",
        "        'outtmpl': temp_video_path,\n",
        "        'format': 'mp4',\n",
        "        'quiet': True\n",
        "    }\n",
        "    try:\n",
        "        with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
        "            print(f\"Downloading video from URL: {url}\")\n",
        "            ydl.download([url])\n",
        "        return temp_video_path\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to download video from URL: {url}. Error: {e}\")\n",
        "        return None\n",
        "\n",
        "# Step 2: Extract frames from the video\n",
        "def extract_frames_from_video(video_path, num_frames=10, target_size=(64, 64)):\n",
        "    try:\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        frame_step = max(1, total_frames // num_frames)\n",
        "        frames = []\n",
        "\n",
        "        for i in range(num_frames):\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, i * frame_step)\n",
        "            ret, frame = cap.read()\n",
        "            if ret:\n",
        "                frame_resized = cv2.resize(frame, target_size)\n",
        "                frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n",
        "                frames.append(frame_rgb)\n",
        "\n",
        "        cap.release()\n",
        "        return np.array(frames)\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting frames from video {video_path}: {e}\")\n",
        "        return np.array([])\n",
        "\n",
        "def process_videos_and_captions(video_urls, captions, num_frames=10):\n",
        "    processed_data = []\n",
        "\n",
        "    for url, caption in zip(video_urls, captions):\n",
        "        try:\n",
        "            # Download video temporarily\n",
        "            temp_video_path = download_video_temp(url)\n",
        "            if temp_video_path is None:\n",
        "                continue\n",
        "\n",
        "            # Extract frames\n",
        "            video_frames = extract_frames_from_video(temp_video_path, num_frames=num_frames)\n",
        "            if video_frames.size == 0:\n",
        "                print(f\"Skipping video {url} as no frames were extracted.\")\n",
        "                continue\n",
        "\n",
        "            # Store the result (frames + caption pair)\n",
        "            processed_data.append((video_frames, caption))\n",
        "\n",
        "            # Delete temporary video to save space\n",
        "            if os.path.exists(temp_video_path):\n",
        "                os.remove(temp_video_path)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing video {url}: {e}\")\n",
        "            continue\n",
        "\n",
        "    return processed_data\n",
        "\n",
        "def preprocess_captions(captions, max_caption_length):\n",
        "    print(\"Preprocessing captions...\")\n",
        "    try:\n",
        "        tokenizer = Tokenizer(oov_token=\"<UNK>\")\n",
        "        tokenizer.fit_on_texts(captions)\n",
        "        word_index = tokenizer.word_index\n",
        "        vocab_size = len(word_index) + 1  # Reserve 0 for padding\n",
        "        sequences = tokenizer.texts_to_sequences(captions)\n",
        "        padded_sequences = pad_sequences(sequences, maxlen=max_caption_length, padding=\"post\")\n",
        "        return tokenizer, vocab_size, padded_sequences\n",
        "    except Exception as e:\n",
        "        print(f\"Error preprocessing captions: {e}\")\n",
        "        return None, 0, None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xw2pf2bpi6oo"
      },
      "outputs": [],
      "source": [
        "def batch_process_videos_and_captions(video_urls, captions, num_frames=10, batch_size = 50, batches = 50):\n",
        "    # has to be tracked manually rn. Replace with last saved video url. DO NOT FORGET: OTHERWISE DUPLICATE DATA\n",
        "    start = 3000 #video_urls.index(\"http://www.youtube.com/watch?v=_XlZ7er6HUQ&feature=youtube_gdata_player\")\n",
        "    current_batch = 0\n",
        "    print(start)\n",
        "    for i in range(start+1, len(video_urls), batch_size):\n",
        "        batch_urls = video_urls[i:i + batch_size]\n",
        "        batch_captions = captions[i:i + batch_size]\n",
        "\n",
        "        # Process batch\n",
        "        batch_data = process_videos_and_captions(batch_urls, batch_captions)\n",
        "\n",
        "        # Save intermediate results\n",
        "        with open(f\"processed_data_batch_{i//batch_size}.pkl\", \"wb\") as f:\n",
        "            pickle.dump(batch_data, f)\n",
        "        print(f\"Batch {i//batch_size} saved!\")\n",
        "        current_batch += 1\n",
        "        if current_batch >= batches:\n",
        "            break\n",
        "\n",
        "    # sip batches into single zip file\n",
        "    zip_batches()\n",
        "    return batch_data\n",
        "\n",
        "def load_batches():\n",
        "    zip_filename = \"processed_data.zip\"\n",
        "    if not os.path.exists(zip_filename):\n",
        "        print(\"No ZIP file found. Processed data cannot be loaded.\")\n",
        "        return []\n",
        "\n",
        "    processed_data = []\n",
        "    with zipfile.ZipFile(zip_filename, \"r\") as zipf:\n",
        "        zipf.extractall()  # Extract all batch files\n",
        "        batch_files = glob.glob(\"processed_data_batch_*.pkl\")\n",
        "        for file in batch_files:\n",
        "            with open(file, \"rb\") as f:\n",
        "                batch_data = pickle.load(f)\n",
        "                processed_data.extend(batch_data)\n",
        "            os.remove(file)  # Clean up extracted files\n",
        "    print(\"Processed data loaded successfully.\")\n",
        "    return processed_data\n",
        "\n",
        "def zip_batches():\n",
        "    batch_files = glob.glob(\"processed_data_batch_*.pkl\")\n",
        "    if not batch_files:\n",
        "        print(\"No batch files to zip.\")\n",
        "        return\n",
        "\n",
        "    zip_filename = \"processed_data.zip\"\n",
        "    with zipfile.ZipFile(zip_filename, \"a\") as zipf:  # Open in append mode\n",
        "        for file in batch_files:\n",
        "            if file not in zipf.namelist():  # Avoid duplicate entries\n",
        "                zipf.write(file)\n",
        "                os.remove(file)  # Remove the file after adding to the zip\n",
        "    print(f\"All batch files added to {zip_filename} and deleted.\")\n",
        "\n",
        "    from google.colab import drive\n",
        "\n",
        "def upload_to_drive(file_path, drive_folder=\"/content/drive/MyDrive/\"):\n",
        "    \"\"\"\n",
        "    Uploads a file to Google Drive and provides a sharable link.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the file you want to upload.\n",
        "        drive_folder (str): Google Drive folder where the file will be uploaded. Default is MyDrive.\n",
        "\n",
        "    Returns:\n",
        "        str: A message with the Google Drive path for sharing.\n",
        "    \"\"\"\n",
        "    zip_batches()\n",
        "    # Mount Google Drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    # Check if file exists\n",
        "    if not os.path.exists(file_path):\n",
        "        return f\"Error: {file_path} does not exist.\"\n",
        "\n",
        "    # Copy file to Google Drive\n",
        "    destination = os.path.join(drive_folder, os.path.basename(file_path))\n",
        "    !cp {file_path} {destination}\n",
        "\n",
        "    # Output Google Drive file path for sharing\n",
        "    shareable_path = f\"https://drive.google.com/file/{os.path.basename(destination)}\"\n",
        "    print(f\"File uploaded successfully to: {destination}\")\n",
        "    print(f\"Share this file using this link: {shareable_path}\")\n",
        "    return shareable_path\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJfrZiCDkXhC"
      },
      "outputs": [],
      "source": [
        "def video_upload(url, temp_video_path=\"/content/temp_analysis.mp4\"):\n",
        "    try:\n",
        "        from yt_dlp import YoutubeDL  # Use yt-dlp for better reliability\n",
        "        ydl_opts = {\n",
        "            'outtmpl': temp_video_path,\n",
        "            'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4',\n",
        "            'quiet': True\n",
        "        }\n",
        "        with YoutubeDL(ydl_opts) as ydl:\n",
        "            print(f\"Downloading video from URL: {url}\")\n",
        "            ydl.download([url])\n",
        "        if not os.path.exists(temp_video_path) or os.path.getsize(temp_video_path) == 0:\n",
        "            print(\"Downloaded video is invalid.\")\n",
        "            return None\n",
        "        return temp_video_path\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to download video from URL: {url}. Error: {e}\")\n",
        "        return None\n",
        "\n",
        "def video_split(video_path, seconds=8, overlap=2):\n",
        "    try:\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        duration = total_frames / fps\n",
        "\n",
        "        clips = []\n",
        "        start_time = 0\n",
        "\n",
        "        while start_time < duration:\n",
        "            end_time = min(start_time + seconds, duration)\n",
        "            clips.append((start_time, end_time))\n",
        "            start_time += seconds - overlap\n",
        "\n",
        "        cap.release()\n",
        "        return clips\n",
        "    except Exception as e:\n",
        "        print(f\"Error splitting video: {e}\")\n",
        "        return []\n",
        "\n",
        "def extract_frames_from_clips(video_path, clips, num_frames=10, target_size=(64, 64)):\n",
        "    \"\"\"\n",
        "    Extracts evenly spaced frames from each video clip.\n",
        "    \"\"\"\n",
        "    frames = []\n",
        "    try:\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "        fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "        for start_time, end_time in clips:\n",
        "            clip = []\n",
        "            start_frame = int(start_time * fps)\n",
        "            end_frame = int(end_time * fps)\n",
        "            frame_step = max(1, (end_frame - start_frame) // num_frames)\n",
        "\n",
        "            for i in range(num_frames):\n",
        "                frame_idx = start_frame + (i * frame_step)\n",
        "                if frame_idx > end_frame:\n",
        "                    break\n",
        "                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
        "                ret, frame = cap.read()\n",
        "                if ret:\n",
        "                    frame_resized = cv2.resize(frame, target_size)\n",
        "                    frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n",
        "                    clip.append(frame_rgb)\n",
        "                else:\n",
        "                    print(f\"Failed to read frame at index {frame_idx}.\")\n",
        "            frames.append(np.array(clip))\n",
        "\n",
        "        cap.release()\n",
        "        print(f\"Extracted {len(frames)} frames from video.\")\n",
        "        return np.array(frames, dtype=np.float32) / 255.0  # Normalize to [0, 1]\n",
        "    except Exception as e:\n",
        "        print(f\"Error extracting frames: {e}\")\n",
        "        return np.array([])\n",
        "\n",
        "def process_video(url):\n",
        "    try:\n",
        "        # Download the video\n",
        "        video_path = video_upload(url)\n",
        "        if not video_path:\n",
        "            print(\"Failed to download video.\")\n",
        "            return None\n",
        "\n",
        "        # Split the video into time-based clips\n",
        "        clips = video_split(video_path)\n",
        "        if not clips:\n",
        "            print(\"Failed to split video into clips.\")\n",
        "            return None\n",
        "\n",
        "        # Extract frames from the clips\n",
        "        video_frames = extract_frames_from_clips(video_path, clips)\n",
        "        if video_frames.size == 0:\n",
        "            print(\"Failed to extract frames.\")\n",
        "            return None\n",
        "\n",
        "        return video_frames\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing video: {e}\")\n",
        "        return None\n",
        "\n",
        "#test\n",
        "#process_video(\"https://www.youtube.com/watch?v=zWH_9VRWn8Y\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xTC8ExYlBFY",
        "outputId": "b0657dfc-dca4-4d00-e6c9-a7223105e7e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 59 batch files to combine.\n",
            "Combined data saved to processed_data.pkl.\n"
          ]
        }
      ],
      "source": [
        "def combine_processed_data(zip_path, output_path=\"processed_data.pkl\"):\n",
        "    # Step 1: Unzip the file\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(\"extracted_data\")  # Extract to a folder called 'extracted_data'\n",
        "\n",
        "    # Step 2: Get all files matching the pattern\n",
        "    batch_files = glob.glob(\"extracted_data/processed_data_batch_*.pkl\")\n",
        "    print(f\"Found {len(batch_files)} batch files to combine.\")\n",
        "\n",
        "    combined_data = []\n",
        "\n",
        "    # Step 3: Load and combine the .pkl files\n",
        "    for file in batch_files:\n",
        "        with open(file, 'rb') as f:\n",
        "            data = pickle.load(f)\n",
        "            if isinstance(data, list):\n",
        "                combined_data.extend(data)  # Combine lists\n",
        "            elif isinstance(data, dict):\n",
        "                combined_data.append(data)  # Add dictionaries to a list\n",
        "            else:\n",
        "                print(f\"Skipping {file}: Unsupported data type.\")\n",
        "\n",
        "    # Step 4: Save the combined data to a new .pkl file\n",
        "    with open(output_path, 'wb') as f:\n",
        "        pickle.dump(combined_data, f)\n",
        "\n",
        "    print(f\"Combined data saved to {output_path}.\")\n",
        "\n",
        "combine_processed_data(\"drive/MyDrive/processed_data.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "id": "E4ST7kMz2id6",
        "outputId": "36f34ea4-e52e-4dfa-c6d5-3866d94c44e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 1576 entries from processed_data.pkl\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)       │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_lstm2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvLSTM2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">40,448</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_lstm2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvLSTM2D</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">221,440</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">327680</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m)       │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_lstm2d (\u001b[38;5;33mConvLSTM2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │          \u001b[38;5;34m40,448\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)      │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv_lstm2d_1 (\u001b[38;5;33mConvLSTM2D\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │         \u001b[38;5;34m221,440\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)      │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed (\u001b[38;5;33mTimeDistributed\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │          \u001b[38;5;34m73,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_1 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_2 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │             \u001b[38;5;34m512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_3 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │         \u001b[38;5;34m147,584\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ time_distributed_4 (\u001b[38;5;33mTimeDistributed\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)     │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m327680\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">484,736</span> (1.85 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m484,736\u001b[0m (1.85 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">484,032</span> (1.85 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m484,032\u001b[0m (1.85 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> (2.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m704\u001b[0m (2.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video frames shape: (1576, 10, 64, 64, 3)\n",
            "X_caption shape: (1576, 19)\n",
            "y_caption shape: (1576, 19)\n"
          ]
        }
      ],
      "source": [
        "def video_encoder(input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # First ConvLSTM2D block\n",
        "    x = ConvLSTM2D(filters=32, kernel_size=(3, 3), padding='same', return_sequences=True, activation=\"relu\")(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Second ConvLSTM2D block\n",
        "    x = ConvLSTM2D(filters=64, kernel_size=(3, 3), padding='same', return_sequences=True, activation=\"relu\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # TimeDistributed Conv2D layers for spatial processing of each frame\n",
        "    x = TimeDistributed(Conv2D(filters=128, kernel_size=(3, 3), padding='same', activation=\"relu\"))(x)\n",
        "    x = TimeDistributed(MaxPooling2D(pool_size=(2, 2)))(x)\n",
        "    x = TimeDistributed(BatchNormalization())(x)\n",
        "\n",
        "    # Another Conv2D block within TimeDistributed\n",
        "    x = TimeDistributed(Conv2D(filters=128, kernel_size=(3, 3), padding='same', activation=\"relu\"))(x)\n",
        "    x = TimeDistributed(MaxPooling2D(pool_size=(2, 2)))(x)\n",
        "\n",
        "    # Apply GlobalAveragePooling2D to collapse spatial dimensions (height, width) for each frame\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Flatten the output for the fully connected layer\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    return Model(inputs, x)\n",
        "\n",
        "\n",
        "# Step 1: Load processed data from the .pkl file\n",
        "def load_processed_data(file_path=\"processed_data.pkl\"):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        combined_data = pickle.load(f)\n",
        "    print(f\"Loaded {len(combined_data)} entries from {file_path}\")\n",
        "    return combined_data\n",
        "\n",
        "# Step 1: Load processed data\n",
        "combined_data = load_processed_data(\"processed_data.pkl\")\n",
        "\n",
        "# Extract video frames and captions\n",
        "video_frames = np.array([item[0] for item in combined_data])  # Assuming item[0] contains video frame arrays\n",
        "captions = [item[1] for item in combined_data]  # Assuming item[1] contains captions as strings\n",
        "\n",
        "tokenizer = Tokenizer(oov_token=\"<UNK>\")\n",
        "tokenizer.fit_on_texts(captions)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# Define encoder\n",
        "input_shape = (10, 64, 64, 3)\n",
        "encoder = video_encoder(input_shape)\n",
        "encoder.summary()\n",
        "vocab_size = len(word_index) + 1  # Include padding (0) in vocab size\n",
        "max_caption_length = 20\n",
        "\n",
        "# Convert captions to padded sequences\n",
        "sequences = tokenizer.texts_to_sequences(captions)\n",
        "padded_captions = pad_sequences(sequences, maxlen=max_caption_length, padding=\"post\")\n",
        "\n",
        "# Prepare inputs and targets\n",
        "X_video = video_frames  # Video frame data\n",
        "X_caption = padded_captions[:, :-1]  # Input captions (exclude the last token)\n",
        "y_caption = padded_captions[:, 1:]  # Target captions (exclude the first token)\n",
        "\n",
        "# Debugging: Verify shapes\n",
        "print(f\"Video frames shape: {X_video.shape}\")  # Should match input_shape of video encoder\n",
        "print(f\"X_caption shape: {X_caption.shape}\")   # Should match input_length of embedding layer\n",
        "print(f\"y_caption shape: {y_caption.shape}\")   # Should match decoder's output shape\n",
        "\n",
        "# Example model adjustment (if input shape mismatch persists)\n",
        "video_input = Input(shape=X_video.shape[1:])  # Shape of video frames\n",
        "caption_input = Input(shape=(max_caption_length,)) # Match X_caption shape\n",
        "\n",
        "# Define Embedding layer with appropriate input_length\n",
        "caption_embedding = Embedding(input_dim=vocab_size, output_dim=256, input_length=X_caption.shape[1])(caption_input)\n",
        "decoder_lstm = LSTM(256, return_sequences=True)(caption_embedding)\n",
        "output = TimeDistributed(Dense(vocab_size, activation=\"softmax\"))(decoder_lstm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LQDLgpNJ0v-"
      },
      "source": [
        "Building Decoder for text generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348
        },
        "id": "vLTq_8QzG1QR",
        "outputId": "259bdfc1-abcc-4ac2-f7e0-f51367c97e23"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">872,448</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                           │                        │                │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ lstm_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3408</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">875,856</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │        \u001b[38;5;34m872,448\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ not_equal (\u001b[38;5;33mNotEqual\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ input_layer_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │        \u001b[38;5;34m525,312\u001b[0m │ embedding_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                           │                        │                │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │              \u001b[38;5;34m0\u001b[0m │ lstm_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m3408\u001b[0m)       │        \u001b[38;5;34m875,856\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,273,616</span> (8.67 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,273,616\u001b[0m (8.67 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,273,616</span> (8.67 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,273,616\u001b[0m (8.67 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def text_decoder(vocab_size, embedding_dim, max_caption_length):\n",
        "    decoder_input = Input(shape=(max_caption_length,))\n",
        "    embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim, mask_zero=True)(decoder_input)\n",
        "    lstm = LSTM(256, return_sequences=True, dropout=0.3, recurrent_dropout=0.3)(embedding)\n",
        "    dropout_output = Dropout(0.3)(lstm)\n",
        "    output = Dense(vocab_size, activation='softmax')(dropout_output)\n",
        "    return Model(decoder_input, output)\n",
        "\n",
        "# Define decoder\n",
        "embedding_dim = 256\n",
        "decoder = text_decoder(vocab_size, embedding_dim, max_caption_length)\n",
        "decoder.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0M2miBgKH0a"
      },
      "source": [
        "Combined Encoder and Decoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 915
        },
        "id": "AekUaznYHjBc",
        "outputId": "ef3c7200-cfb1-40c3-dc90-447f8b5db5ca"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_3\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_3\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)  │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv_lstm2d_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │         <span style=\"color: #00af00; text-decoration-color: #00af00\">40,448</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvLSTM2D</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_4     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>) │            <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │ conv_lstm2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv_lstm2d_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">221,440</span> │ batch_normalization_4… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ConvLSTM2D</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_5     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>) │            <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv_lstm2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ time_distributed_6        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>,     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ batch_normalization_5… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ time_distributed_7        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ time_distributed_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ time_distributed_8        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ time_distributed_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ time_distributed_9        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>,     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ time_distributed_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ time_distributed_10       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ time_distributed_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)         │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_7     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>,     │            <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ time_distributed_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                   │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_5             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">327680</span>)         │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_7… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">872,448</span> │ input_layer_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">83,886,336</span> │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">83,886,336</span> │ flatten_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">525,312</span> │ embedding_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     │\n",
              "│                           │                        │                │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],         │\n",
              "│                           │                        │                │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3408</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">875,856</span> │ lstm_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]           │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m3\u001b[0m)  │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv_lstm2d_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m) │         \u001b[38;5;34m40,448\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mConvLSTM2D\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_4     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m) │            \u001b[38;5;34m128\u001b[0m │ conv_lstm2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ conv_lstm2d_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m) │        \u001b[38;5;34m221,440\u001b[0m │ batch_normalization_4… │\n",
              "│ (\u001b[38;5;33mConvLSTM2D\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_5     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m) │            \u001b[38;5;34m256\u001b[0m │ conv_lstm2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ time_distributed_6        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m,     │         \u001b[38;5;34m73,856\u001b[0m │ batch_normalization_5… │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)         │ \u001b[38;5;34m128\u001b[0m)                   │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ time_distributed_7        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,     │              \u001b[38;5;34m0\u001b[0m │ time_distributed_6[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)         │ \u001b[38;5;34m128\u001b[0m)                   │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ time_distributed_8        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,     │            \u001b[38;5;34m512\u001b[0m │ time_distributed_7[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)         │ \u001b[38;5;34m128\u001b[0m)                   │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ time_distributed_9        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m,     │        \u001b[38;5;34m147,584\u001b[0m │ time_distributed_8[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)         │ \u001b[38;5;34m128\u001b[0m)                   │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ time_distributed_10       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,     │              \u001b[38;5;34m0\u001b[0m │ time_distributed_9[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)         │ \u001b[38;5;34m128\u001b[0m)                   │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ batch_normalization_7     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m,     │            \u001b[38;5;34m512\u001b[0m │ time_distributed_10[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)      │ \u001b[38;5;34m128\u001b[0m)                   │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ input_layer_5             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)              │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m327680\u001b[0m)         │              \u001b[38;5;34m0\u001b[0m │ batch_normalization_7… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │        \u001b[38;5;34m872,448\u001b[0m │ input_layer_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m83,886,336\u001b[0m │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │     \u001b[38;5;34m83,886,336\u001b[0m │ flatten_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm_2 (\u001b[38;5;33mLSTM\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │        \u001b[38;5;34m525,312\u001b[0m │ embedding_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     │\n",
              "│                           │                        │                │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],         │\n",
              "│                           │                        │                │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m, \u001b[38;5;34m3408\u001b[0m)       │        \u001b[38;5;34m875,856\u001b[0m │ lstm_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]           │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">170,531,024</span> (650.52 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m170,531,024\u001b[0m (650.52 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">170,530,320</span> (650.52 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m170,530,320\u001b[0m (650.52 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> (2.75 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m704\u001b[0m (2.75 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def video_to_text_model(input_shape, vocab_size, embedding_dim, max_caption_length):\n",
        "    # Encoder\n",
        "    encoder = video_encoder(input_shape)\n",
        "    video_features = encoder.output  # Shape: (None, feature_dim)\n",
        "\n",
        "    # Decoder\n",
        "    decoder_input = Input(shape=(max_caption_length - 1,))  # Input captions\n",
        "    embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim, mask_zero=True)(decoder_input)  # Shape: (None, max_caption_length-1, embedding_dim)\n",
        "\n",
        "    # Use video features as the initial state of the LSTM\n",
        "    video_state_h = Dense(256, activation='relu')(video_features)  # Hidden state\n",
        "    video_state_c = Dense(256, activation='relu')(video_features)  # Cell state\n",
        "\n",
        "    lstm = LSTM(256, return_sequences=True)(embedding, initial_state=[video_state_h, video_state_c])\n",
        "\n",
        "    # Output layer\n",
        "    output = Dense(vocab_size, activation='softmax')(lstm)  # Shape: (None, max_caption_length-1, vocab_size)\n",
        "\n",
        "    return Model([encoder.input, decoder_input], output)\n",
        "\n",
        "model = video_to_text_model(input_shape, vocab_size, embedding_dim, max_caption_length)\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pyc4lEFcA7hA"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKTHZ0oXPFVI",
        "outputId": "ad3338e3-ee2e-465e-d740-57695831c4d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5243s\u001b[0m 53s/step - accuracy: 0.5556 - loss: 7.4519\n",
            "Epoch 2/30\n",
            "\u001b[1m37/99\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m54:39\u001b[0m 53s/step - accuracy: 0.6167 - loss: 6.7450"
          ]
        }
      ],
      "source": [
        "\n",
        "# Train the model\n",
        "epochs = 30\n",
        "batch_size = 16\n",
        "model.fit([X_video, X_caption], y_caption, epochs=epochs, batch_size=batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-0oFMfgKRoj"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c133xcUgKVHg"
      },
      "source": [
        "Generate Captions/Alt text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "9oVzCKo1Kbod",
        "outputId": "4bf31fa5-3000-4843-bb84-2d3415be7bf0"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'process_video' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7af7fa788714>\u001b[0m in \u001b[0;36m<cell line: 51>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mlink\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://www.youtube.com/watch?v=zWH_9VRWn8Y\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mclip_frames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip_frames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip_frames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'process_video' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Input\n",
        "\n",
        "def generate_caption(model, tokenizer, clip_frames, max_caption_length):\n",
        "    \"\"\"\n",
        "    Generate a transcript for a video using the encoder-decoder model, processing clips individually.\n",
        "    \"\"\"\n",
        "    # Initialize the complete transcript\n",
        "    transcript = []\n",
        "\n",
        "    # Process each set of frames (clip) in the array\n",
        "    for clip_index, frames in enumerate(clip_frames):\n",
        "        print(f\"Processing clip {clip_index + 1}/{len(clip_frames)}...\")\n",
        "\n",
        "        # Initialize the decoder input with the <start> token\n",
        "        start_token = tokenizer.word_index.get(\"<start>\", 1)  # Default to 1 if <start> is not in the vocab\n",
        "        decoder_input = np.zeros((1, max_caption_length - 1))\n",
        "        decoder_input[0, 0] = start_token\n",
        "\n",
        "        # Initialize generated caption for the clip\n",
        "        generated_caption = []\n",
        "\n",
        "        # Generate the caption word by word\n",
        "        for i in range(1, max_caption_length - 1):\n",
        "            # Predict the next word based on the input so far\n",
        "            # Reshape frames to add a batch dimension\n",
        "            frames_reshaped = frames[np.newaxis, ...]  # Add batch dimension\n",
        "            predictions = model.predict([frames_reshaped, decoder_input])\n",
        "\n",
        "            # Select the word with the highest probability\n",
        "            next_word_index = np.argmax(predictions[0, i - 1, :])\n",
        "\n",
        "            # Stop if the <end> token is generated\n",
        "            if next_word_index == tokenizer.word_index.get(\"<end>\", 2):  # Default to 2 if <end> is not in the vocab\n",
        "                break\n",
        "\n",
        "            # Append the predicted word to the caption\n",
        "            generated_caption.append(tokenizer.index_word.get(next_word_index, \"<UNK>\"))\n",
        "\n",
        "            # Update the decoder input with the predicted word\n",
        "            decoder_input[0, i] = next_word_index\n",
        "\n",
        "        # Join the words into a caption and append to the transcript\n",
        "        transcript.append(\" \".join(generated_caption))\n",
        "\n",
        "    # Return the complete transcript as a single string\n",
        "    return \" \".join(transcript)\n",
        "\n",
        "link = \"https://www.youtube.com/watch?v=zWH_9VRWn8Y\"\n",
        "clip_frames = process_video(link)\n",
        "print(len(clip_frames))\n",
        "print(clip_frames[0].shape)\n",
        "# Generate a caption for the unseen video\n",
        "caption = generate_caption(model, tokenizer, clip_frames, max_caption_length)\n",
        "print(\"Generated caption:\", caption)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YJaQ-k9mFVVm"
      },
      "source": [
        "Generate caption on video from training set"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}